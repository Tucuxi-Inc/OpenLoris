# Environment Configuration
ENVIRONMENT=development
DEBUG=true

# Security
SECRET_KEY=your-secret-key-here-change-in-production

# Database (use these ports for Docker)
DATABASE_URL=postgresql://loris:password@localhost:5435/loris

# Redis Cache
REDIS_URL=redis://localhost:6385

# ============================================
# AI Provider Configuration
# ============================================
# Choose your AI provider: local_ollama, cloud_anthropic, cloud_bedrock, cloud_azure
AI_PROVIDER=local_ollama

# Option 1: Ollama (Local - No API key needed, data stays on your machine)
# Install from https://ollama.ai and run: ollama pull llama3.2
OLLAMA_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.2

# Option 2: Anthropic Claude (Cloud - Highest quality)
# Get API key from https://console.anthropic.com
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Option 3: AWS Bedrock (Enterprise - data stays in your AWS account)
# AWS_REGION=us-east-1
# AWS_BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# Option 4: Azure OpenAI (Enterprise - data stays in your Azure tenant)
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_KEY=your-azure-key
# AZURE_OPENAI_DEPLOYMENT=your-deployment-name

# ============================================

# CORS Settings (comma-separated)
ALLOWED_ORIGINS=http://localhost:3005,http://localhost:8005

# File Upload Settings
MAX_UPLOAD_SIZE=10485760
UPLOAD_DIR=uploads

# Rate Limiting
RATE_LIMIT_REQUESTS=100

# Pagination
DEFAULT_PAGE_SIZE=20
MAX_PAGE_SIZE=100
